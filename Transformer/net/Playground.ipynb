{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PositionwiseFFN import PositionwiseFFN\n",
    "from DotProductAttention import DotProductAttention\n",
    "from MultiHeadAttention import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test PFFN\n",
    "dmodel=64\n",
    "inlen = 60\n",
    "ffn = PositionwiseFFN(dmodel)\n",
    "x = torch.rand(32, 10, 64)\n",
    "assert ffn(x).shape == x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dot queries = torch.normal(0, 1, (2, 1, 2))\n",
    "### Test code from d2l.ai\n",
    "queries = torch.normal(0, 1, (2, 10, 2))\n",
    "keys = torch.normal(0, 1, (2, 10, 2))\n",
    "values = torch.normal(0, 1, (2, 10, 4))\n",
    "valid_lens = torch.tensor([2, 6])\n",
    "\n",
    "attention = DotProductAttention(dropout=0.5)\n",
    "attention.eval()\n",
    "assert attention(queries, keys, values).shape == (2, 10, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MHA\n",
    "d_model, num_heads = 100, 5\n",
    "attention = MultiHeadAttention(d_model, num_heads, 0.5)\n",
    "batch_size = 2\n",
    "\n",
    "X = torch.ones((batch_size, inlen, d_model))\n",
    "\n",
    "assert attention(X, X, X, \"None\").shape == (batch_size, inlen, d_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d65bdc5d2ce5f47a5dacc71f251d002481db9b35ba5522b1e89f66f66f443b2e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
