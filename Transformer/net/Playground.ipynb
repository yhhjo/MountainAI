{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PositionwiseFFN import PositionwiseFFN\n",
    "from DotProductAttention import DotProductAttention\n",
    "from MultiHeadAttention import MultiHeadAttention\n",
    "from Encoder import EncoderBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test PFFN\n",
    "d_model=64\n",
    "ffn = PositionwiseFFN(dmodel)\n",
    "x = torch.rand(32, 10, d_model)\n",
    "\n",
    "assert ffn(x).shape == x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dot queries = torch.normal(0, 1, (2, 1, 2))\n",
    "### Test code from d2l.ai\n",
    "queries = torch.normal(0, 1, (2, 10, 2))\n",
    "keys = torch.normal(0, 1, (2, 10, 2))\n",
    "values = torch.normal(0, 1, (2, 10, 4))\n",
    "valid_lens = torch.tensor([2, 6])\n",
    "\n",
    "attention = DotProductAttention(dropout=0.5)\n",
    "attention.eval()\n",
    "assert attention(queries, keys, values).shape == (2, 10, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MHA\n",
    "d_model, num_heads, inlen = 100, 5, 20\n",
    "attention = MultiHeadAttention(d_model, d_model, d_model, num_heads)\n",
    "batch_size = 2\n",
    "\n",
    "X = torch.ones((batch_size, inlen, d_model))\n",
    "\n",
    "assert attention(X, X, X, \"None\").shape == (batch_size, inlen, d_model)\n",
    "assert attention(X, X, X, \"future\").shape == (batch_size, inlen, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize shaping of attention and masks\n",
    "q = torch.rand((2,5,8))\n",
    "v = torch.rand((2,5,8))\n",
    "k = q\n",
    "\n",
    "K = q.shape[1]  # Sequence length\n",
    "\n",
    "dk = q.shape[1]**.5 \n",
    "I = (q@k.transpose(1,2))\n",
    "\n",
    "future_mask = torch.triu(torch.ones((K, K)), diagonal=1).bool()\n",
    "I = I.masked_fill(future_mask, float('-inf'))\n",
    "a = nn.functional.softmax(I/dk, dim=-1)@v \n",
    "#print(f\"I = {I}\")\n",
    "#print(f\"Attention = {a}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Encoder\n",
    "dmodel=64\n",
    "e = EncoderBlock(dmodel, dmodel, dmodel, h=8, dropout=0.2)\n",
    "x = torch.rand(32, 10, dmodel)\n",
    "assert e(x).shape == x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d65bdc5d2ce5f47a5dacc71f251d002481db9b35ba5522b1e89f66f66f443b2e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
