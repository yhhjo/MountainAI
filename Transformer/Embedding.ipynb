{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "module_dir = '../DataGeneration/Python'\n",
    "if module_dir not in sys.path:\n",
    "    sys.path.append(module_dir)\n",
    "    \n",
    "import Sample\n",
    "import Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../Dataset/CC10k.npy'\n",
    "BATCH_SIZE = 32\n",
    "D_MODEL = 64  \n",
    "N_WORKERS = 0\n",
    "\n",
    "# From data\n",
    "d_input = 10+4*(10) # 10 Ages + 4 thermochronometers*(10 samples))\n",
    "d_output = 7+3*5+5  # Output sequence 7 constants + 3 exhumation_history params * 5 rates + 5 uplift rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoData = Dataloader.formattedLoader(d_input, d_output, DATASET_PATH) # Get input data formatted for network\n",
    "data_train, data_val, data_test = random_split(geoData, (9000, 500, 500))\n",
    "\n",
    "dataloader_train = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
    "\n",
    "dataloader_val = DataLoader(data_val, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
    "\n",
    "dataloader_test = DataLoader(data_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(array([-0.,  3.,  6.,  8., 10., 12., 14., 16., 18., 20.]), [3.892, 5.922, 7.8260000000000005, 8.666, 9.49, 10.306000000000001, 11.122, 11.934000000000001, 12.842, 13.788], [2.928, 5.122, 7.192, 8.268, 9.126, 9.964, 10.794, 11.618, 12.476, 13.418000000000001], [0.002, 4.16, 6.368, 7.7540000000000004, 8.706, 9.58, 10.432, 11.272, 12.106, 13.028], [0.002, 2.7960000000000003, 5.394, 6.886, 8.186, 9.134, 10.022, 10.888, 11.738, 12.616]),\n",
       "       <Sample.Sample object at 0x7fe159eed580>], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define embedding layer\n",
    "embedding_layer = nn.Linear(d_input, D_MODEL)\n",
    "\n",
    "# Define a batch of input data points\n",
    "input_data = torch.randn(BATCH_SIZE, 10+4*(10))  \n",
    "# Normalize the input\n",
    "i = np.array([*x[0]])\n",
    "i = ((i - np.mean(i, axis=1, keepdims=True)) / np.std(i, axis=1, keepdims=True)).flatten()\n",
    "\n",
    "# Pass the inputs through the embedding layer\n",
    "embeddings = embedding_layer(inputs)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d65bdc5d2ce5f47a5dacc71f251d002481db9b35ba5522b1e89f66f66f443b2e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
